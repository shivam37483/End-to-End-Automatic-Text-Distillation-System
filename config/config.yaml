artifacts_root: artifacts      # Root directory for all artifacts

data_ingestion:
  root_dir: artifacts/data_ingestion         #create a directory for data_ingestion 
  source_URL: https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip     #download the data from the source URL
  local_data_file: artifacts/data_ingestion/data.zip            #create a local data file for the downloaded data
  unzip_dir: artifacts/data_ingestion              #unzip the data in the data_ingestion directory


data_validation:
  root_dir: artifacts/data_validation                    #We will create a new directory for data_validation which will save all the status_file containing validation of dataset
  status_file: artifacts/data_validation/status.txt
  ALL_REQUIRED_FILES: ["train", "test", "validation"]


data_transformation:
  root_dir: artifacts/data_transformation                #We will create a new directory for data_transformation which will save all the transformed data 
  data_path: artifacts/data_ingestion/samsum_dataset         #Contains the data from data ingestion on which we will apply transformation
  tokenizer_name: google/pegasus-cnn_dailymail            #It will automatically download the model 